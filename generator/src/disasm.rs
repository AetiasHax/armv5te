use std::cmp::Ordering;

use anyhow::{bail, Context, Result};
use proc_macro2::{Literal, Span, TokenStream};
use quote::{format_ident, quote};
use syn::Ident;

use crate::{
    isa::{Isa, Opcode},
    token::HexLiteral,
};

pub fn generate_disasm(isa: &Isa, bucket_bitmask: u32) -> Result<TokenStream> {
    // To improve the search, the opcodes are sorted by bucket index. Read further for more info.
    let sorted_opcodes = sort_opcodes(isa, bucket_bitmask);
    let (opcode_patterns_tokens, opcode_enum_tokens, opcode_mnemonics_tokens, num_opcodes_token) =
        generate_opcode_tokens(&sorted_opcodes);

    // We could use a binary search on sorted_opcodes, but we can do better. We generate a lookup table which maps a bucket
    // index to the range of opcodes in sorted_opcodes with that bucket index.
    let bucket_count = 1 << bucket_bitmask.count_ones();
    let lookup_table = create_lookup_table(bucket_count, sorted_opcodes);
    let lookup_table_tokens = generate_lookup_table_tokens(lookup_table);

    // Generate bucket index function
    let bucket_index_tokens = generate_bucket_index_function(bucket_bitmask);

    // Generate field accessors
    let field_accessors_tokens = generate_field_accessors(isa);

    // Generate modifier case enums
    let case_enums_tokens = generate_modifier_case_enums(isa);

    // Generate modifier accessors
    let modifier_accessors_tokens = generate_modifier_accessors(isa)?;

    // Generate argument types
    let argument_enum_tokens = generate_argument_enums(isa)?;

    let bucket_count = Literal::u8_unsuffixed(bucket_count);
    let max_args = Literal::usize_unsuffixed(isa.get_max_args()?);
    Ok(quote! {
        #![cfg_attr(rustfmt, rustfmt_skip)]
        #[comment = " Generated by armv5te-generator. Do not edit!"]

        use crate::disasm::Ins;

        #[doc = " This lookup table limits the search to at most 5 opcodes by reading 6 pre-selected bits from the instruction."]
        static LOOKUP_TABLE: [(u8, u8); #bucket_count] = [#lookup_table_tokens];

        #[doc = " Maps an instruction to a bucket in the lookup table."]
        #bucket_index_tokens

        #[doc = " These tuples contain a bitmask and pattern for each opcode."]
        static OPCODE_PATTERNS: [(u32, u32); #num_opcodes_token] = [#opcode_patterns_tokens];

        #[doc = " These are the mnemonics of each opcode. Some mnemonics are duplicated due to them having multiple formats."]
        static OPCODE_MNEMONICS: [&str; #num_opcodes_token] = [#opcode_mnemonics_tokens];

        #[derive(Clone, Copy, Debug, Default, PartialEq, Eq)]
        #[repr(u8)]
        #[non_exhaustive]
        pub enum Opcode {
            #[doc = " Illegal or unknown"]
            #[default]
            Illegal = u8::MAX,
            #opcode_enum_tokens
        }
        impl Opcode {
            #[inline]
            pub fn find(code: u32) -> Self {
                let index = bucket_index(code);
                let lookup = LOOKUP_TABLE[index];
                if lookup.0 == lookup.1 {
                    return Self::Illegal;
                }
                for i in lookup.0..lookup.1 {
                    let (bitmask, pattern) = OPCODE_PATTERNS[i as usize];
                    if (code & bitmask) == pattern {
                        return unsafe { core::mem::transmute::<u8, Opcode>(i) };
                    }
                }
                Self::Illegal
            }
            pub fn mnemonic(self) -> &'static str {
                OPCODE_MNEMONICS[self as usize]
            }
            pub fn count() -> usize {
                #num_opcodes_token
            }
        }

        impl Ins {
            #field_accessors_tokens
            #modifier_accessors_tokens
        }

        #case_enums_tokens

        pub type Arguments = [Argument; #max_args];
        #argument_enum_tokens
    })
}

fn generate_argument_enums(isa: &Isa) -> Result<TokenStream> {
    let mut argument_variants = TokenStream::new();
    let mut argument_sub_enum_tokens = TokenStream::new();
    for arg in isa.args.iter() {
        let variant_name = arg.variant_name();
        let variant_ident = Ident::new(&variant_name, Span::call_site());
        let doc = arg.doc();

        let contents = match (&arg.values, arg.signed, arg.boolean) {
            (None, true, false) => quote! { (i32) },
            (None, false, true) => quote! { (bool) },
            (None, false, false) => quote! { (u32) },
            (Some(values), false, false) => {
                // Create enum with the same name as the argument
                let mut sub_variants = TokenStream::new();
                for value in values.iter() {
                    let sub_variant_name = value.variant_name();
                    let sub_variant_ident = Ident::new(&sub_variant_name, Span::call_site());
                    let sub_variant_value = Literal::u8_unsuffixed(value.value);
                    let sub_doc = value.doc();
                    let sub_doc = if !sub_doc.is_empty() {
                        quote! { #[doc = #sub_doc] }
                    } else {
                        quote! {}
                    };
                    sub_variants.extend(quote! {
                        #sub_doc
                        #sub_variant_ident = #sub_variant_value,
                    });
                }

                argument_sub_enum_tokens.extend(quote! {
                    #[derive(Clone, Copy, PartialEq, Eq)]
                    #[repr(u8)]
                    pub enum #variant_ident {
                        #sub_variants
                    }
                });

                if !arg.is_continuous() {
                    bail!("No support for discontinuous args currently")
                }
                let min_value = values.iter().min_by_key(|v| v.value).unwrap();
                let max_value = values.iter().max_by_key(|v| v.value).unwrap();
                let min_value_token = Literal::u8_unsuffixed(min_value.value);
                let max_value_token = Literal::u8_unsuffixed(max_value.value);
                argument_sub_enum_tokens.extend(quote! {
                    impl #variant_ident {
                        pub fn parse(value: u8) -> Option<Self> {
                            if value >= #min_value_token && value <= #max_value_token {
                                unsafe { Some(std::mem::transmute::<u8, Self>(value)) }
                            } else {
                                None
                            }
                        }
                    }
                });

                quote! { (#variant_ident) }
            }

            (None, true, true) => bail!("Can't generate argument variant '{}' which is signed and boolean", arg.name),
            (Some(_), true, true) => bail!(
                "Can't generate argument variant '{}' which has values and is signed and boolean",
                arg.name
            ),
            (Some(_), true, false) => bail!(
                "Can't generate argument variant '{}' which has values and is signed",
                arg.name
            ),
            (Some(_), false, true) => bail!(
                "Can't generate argument variant '{}' which has values and is boolean",
                arg.name
            ),
        };

        argument_variants.extend(quote! {
            #[doc = #doc]
            #variant_ident #contents,
        })
    }
    let argument_enum_tokens = quote! {
        #[derive(Default, Clone, Copy, PartialEq, Eq)]
        pub enum Argument {
            #[default]
            None,
            #argument_variants
        }
        #argument_sub_enum_tokens
    };
    Ok(argument_enum_tokens)
}

fn generate_modifier_accessors(isa: &Isa) -> Result<TokenStream> {
    let mut modifier_accessors_tokens = TokenStream::new();
    for modifier in isa.modifiers.iter() {
        let (ret_type, inner) = match (modifier.bitmask, modifier.pattern, &modifier.cases) {
            (Some(bitmask), Some(pattern), None) => {
                let bitmask_token = HexLiteral(bitmask);
                let pattern_token = HexLiteral(pattern);
                (
                    Ident::new("bool", Span::call_site()),
                    quote! { (self.code & #bitmask_token) == #pattern_token },
                )
            }
            (bitmask, None, Some(cases)) => {
                let enum_name = modifier.enum_name();
                let enum_ident = Ident::new(&enum_name, Span::call_site());

                let sorted_cases = {
                    let mut sorted_cases = Vec::from(cases.clone());
                    // When bitmask A is a subset of B, then B must be first, otherwise we will never choose B
                    sorted_cases.sort_by_key(|case| 32 - case.bitmask.unwrap_or(0).count_ones());
                    sorted_cases
                };

                if let Some(bitmask) = bitmask {
                    let bitmask_token = HexLiteral(bitmask);
                    let mut match_tokens = TokenStream::new();
                    for case in sorted_cases.iter() {
                        let pattern_token = HexLiteral(case.pattern);
                        let variant_name = case.variant_name();
                        let variant_ident = Ident::new(&variant_name, Span::call_site());
                        match_tokens.extend(quote! {
                            #pattern_token => #enum_ident::#variant_ident,
                        });
                    }

                    (
                        enum_ident,
                        quote! {
                            match self.code & #bitmask_token {
                                #match_tokens
                                _ => unreachable!(),
                            }
                        },
                    )
                } else {
                    let mut if_tokens = vec![];
                    for case in sorted_cases.iter() {
                        let bitmask = case.bitmask.with_context(|| {
                            format!("Modifier case '{}' in modifier '{}' has no bitmask", case.name, modifier.name)
                        })?;
                        let bitmask_token = HexLiteral(bitmask);
                        let pattern_token = HexLiteral(case.pattern);
                        let variant_name = case.variant_name();
                        let variant_ident = Ident::new(&variant_name, Span::call_site());
                        if_tokens.push(quote! {
                            if (self.code & #bitmask_token) == #pattern_token {
                                #enum_ident::#variant_ident
                            }
                        });
                    }

                    (
                        enum_ident,
                        quote! {
                            #(#if_tokens)else*
                            else {
                                unreachable!()
                            }
                        },
                    )
                }
            }
            (None, Some(_), None) => bail!("Can't generate modifier accessor '{}' with only a pattern", modifier.name),
            (_, Some(_), Some(_)) => bail!(
                "Can't generate modifier accessor '{}' with a pattern and cases",
                modifier.name
            ),
            (Some(_), None, None) => bail!("Can't generate modifier accessor '{}' with only a bitmask", modifier.name),
            (None, None, None) => bail!(
                "Can't generate modifier accessor '{}' without a pattern, bitmask and/or cases",
                modifier.name
            ),
        };

        let doc = modifier.doc();
        let fn_name = Ident::new(&modifier.accessor_name(), Span::call_site());

        modifier_accessors_tokens.extend(quote! {
            #[doc = #doc]
            #[inline(always)]
            pub const fn #fn_name(&self) -> #ret_type {
                #inner
            }
        })
    }
    Ok(modifier_accessors_tokens)
}

fn generate_modifier_case_enums(isa: &Isa) -> TokenStream {
    let mut case_enums_tokens = TokenStream::new();
    for modifier in isa.modifiers.iter() {
        if let Some(cases) = &modifier.cases {
            let mut variants_tokens = TokenStream::new();
            for case in cases.iter() {
                let variant_name = case.variant_name();
                let variant_ident = Ident::new(&variant_name, Span::call_site());
                let doc = case.doc();
                variants_tokens.extend(quote! {
                    #[doc = #doc]
                    #variant_ident,
                });
            }
            let enum_name = modifier.enum_name();
            let enum_ident = Ident::new(&enum_name, Span::call_site());
            let doc = modifier.doc();
            case_enums_tokens.extend(quote! {
                #[doc = #doc]
                pub enum #enum_ident {
                    #variants_tokens
                }
            })
        }
    }
    case_enums_tokens
}

fn generate_field_accessors(isa: &Isa) -> TokenStream {
    let mut field_accessors_tokens = TokenStream::new();
    for field in isa.fields.iter() {
        let num_bits = field.bits.0.len();
        let shift = field.bits.0.start;
        let bitmask = HexLiteral(((1 << num_bits) - 1) << shift);
        let shift_token = Literal::u8_unsuffixed(shift);

        let body_tokens = if shift > 0 && num_bits > 1 {
            quote! { (self.code & #bitmask) >> #shift_token }
        } else {
            quote! { self.code & #bitmask }
        };

        let doc = field.doc();
        let fn_name = Ident::new(&field.accessor_name(), Span::call_site());
        let (ret_type, inner) = match num_bits {
            1 => (Ident::new("bool", Span::call_site()), quote! { (#body_tokens) != 0 }),
            2..=8 => (Ident::new("u8", Span::call_site()), quote! { (#body_tokens) as u8 }),
            9..=16 => (Ident::new("u16", Span::call_site()), quote! { (#body_tokens) as u16 }),
            17..=32 => (Ident::new("u32", Span::call_site()), quote! { (#body_tokens) as u32 }),
            _ => unreachable!(),
        };

        field_accessors_tokens.extend(quote! {
            #[doc = #doc]
            #[inline(always)]
            pub const fn #fn_name(&self) -> #ret_type {
                #inner
            }
        });
    }
    field_accessors_tokens
}

fn generate_bucket_index_function(bucket_bitmask: u32) -> TokenStream {
    let mut bucket_index_body_tokens = TokenStream::new();
    bucket_index_body_tokens.extend(quote! {
        let mut index = 0;
    });
    let mut bitmask = bucket_bitmask;
    let mut total_shift = 0;
    let mut bucket_bits = 0;
    while bitmask != 0 {
        let zero_shift = bitmask.trailing_zeros();
        bitmask >>= zero_shift;
        let one_shift = bitmask.trailing_ones();
        let bits = (1 << one_shift) - 1;
        bitmask >>= one_shift;

        total_shift += zero_shift;
        let mask_token = HexLiteral(bits << total_shift);
        let bucket_shift: i32 = total_shift as i32 - bucket_bits as i32;
        let shift_token = Literal::i32_unsuffixed(bucket_shift.abs());
        match bucket_shift.cmp(&0) {
            Ordering::Greater => bucket_index_body_tokens.extend(quote! {
                index |= (code & #mask_token) >> #shift_token;
            }),
            Ordering::Less => bucket_index_body_tokens.extend(quote! {
                index |= (code & #mask_token) << #shift_token;
            }),
            Ordering::Equal => bucket_index_body_tokens.extend(quote! {
                index |= code & #mask_token;
            }),
        }
        bucket_bits += one_shift;
        total_shift += one_shift;
    }
    bucket_index_body_tokens.extend(quote! {
        index.try_into().unwrap()
    });
    let mut bucket_index_tokens = TokenStream::new();
    bucket_index_tokens.extend(quote! {
        fn bucket_index(code: u32) -> usize {
            #bucket_index_body_tokens
        }
    });
    bucket_index_tokens
}

fn generate_lookup_table_tokens(lookup_table: Vec<(u8, u8)>) -> TokenStream {
    let mut lookup_table_tokens = TokenStream::new();
    for entry in lookup_table {
        let start = Literal::u8_unsuffixed(entry.0);
        let end = Literal::u8_unsuffixed(entry.1);
        lookup_table_tokens.extend(quote! { (#start, #end), });
    }
    lookup_table_tokens
}

fn create_lookup_table(bucket_count: u8, sorted_opcodes: Vec<(Opcode, u8)>) -> Vec<(u8, u8)> {
    (0..bucket_count)
        .map(|bucket| {
            let start = sorted_opcodes
                .iter()
                .position(|(_, b)| *b == bucket)
                .map(|p| p.try_into().unwrap())
                .unwrap_or(0);
            let end = sorted_opcodes
                .iter()
                .rev()
                .position(|(_, b)| *b == bucket)
                .map(|p| (sorted_opcodes.len() - p).try_into().unwrap())
                .unwrap_or(0);
            (start, end)
        })
        .collect()
}

fn generate_opcode_tokens(sorted_opcodes: &[(Opcode, u8)]) -> (TokenStream, TokenStream, TokenStream, Literal) {
    let mut opcode_patterns_tokens = TokenStream::new();
    let mut opcode_enum_tokens = TokenStream::new();
    let mut opcode_mnemonics_tokens = TokenStream::new();
    let num_opcodes_token = Literal::usize_unsuffixed(sorted_opcodes.len());
    for (i, (opcode, _)) in sorted_opcodes.iter().enumerate() {
        let bitmask = HexLiteral(opcode.bitmask);
        let pattern = HexLiteral(opcode.pattern);
        let doc = opcode.doc();
        opcode_patterns_tokens.extend(quote! {
            #[comment = #doc]
            (#bitmask, #pattern),
        });

        let name = &opcode.name();
        opcode_mnemonics_tokens.extend(quote! { #name, });

        let enum_name = Ident::new(&opcode.enum_name(), Span::call_site());
        let enum_value = Literal::u8_unsuffixed(i.try_into().unwrap());
        opcode_enum_tokens.extend(quote! {
            #[doc = #doc]
            #enum_name = #enum_value,
        });
    }
    (
        opcode_patterns_tokens,
        opcode_enum_tokens,
        opcode_mnemonics_tokens,
        num_opcodes_token,
    )
}

fn sort_opcodes(isa: &Isa, bucket_bitmask: u32) -> Vec<(Opcode, u8)> {
    let mut opcodes: Vec<(Opcode, u8)> = isa
        .opcodes
        .iter()
        .cloned()
        .map(|op| {
            let bucket = op.bucket_index(bucket_bitmask);
            (op, bucket.try_into().unwrap())
        })
        .collect();
    opcodes.sort_by(|(a, bucket_a), (b, bucket_b)| {
        bucket_a
            .cmp(bucket_b)
            // When bitmask A is a subset of B, then B must be first, otherwise Opcode::find will never choose B
            .then(b.bitmask.count_ones().cmp(&a.bitmask.count_ones()))
    });
    opcodes
}
